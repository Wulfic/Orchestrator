{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f8d9c3e",
   "metadata": {},
   "source": [
    "# Condensed Phase-by-Phase Implementation Plan\n",
    "\n",
    "## Phase 1: Environment Setup\n",
    "- **Install Python 3.10+** and create an isolated environment (`venv` or `conda`).\n",
    "- **Install required packages:** `requests`, `websockets`, `openai` (if needed).\n",
    "- **Start LM Studio**, note its API endpoint (default: `http://localhost:1234/v1/chat/completions`).\n",
    "- **Choose and verify Copilot output file location and format** (plain text or JSON).\n",
    "\n",
    "## Phase 2: Communication Bridge\n",
    "- Implement `query_lm_studio(prompt)` to send prompts via HTTP and return JSON.\n",
    "- Add error handling for HTTP status codes and timeouts.\n",
    "- Define a simple JSON message schema for agent requests and responses.\n",
    "- Log all API interactions for debugging.\n",
    "\n",
    "## Phase 3: Copilot Output Integration\n",
    "- Write `read_copilot_output()` and `write_copilot_output(data)` functions.\n",
    "- Test file I/O operations to ensure correct serialization (e.g., JSON parsing).\n",
    "- Standardize file naming conventions and directory structure.\n",
    "- Handle file permission errors and path validations.\n",
    "\n",
    "## Phase 4: Orchestrator Agent\n",
    "- Create an `OrchestratorAgent` class with:\n",
    "  - `add_step(description, action)`\n",
    "  - `run_next_step()`\n",
    "- Maintain `steps`, `current_step`, and a persistent state file for recovery.\n",
    "- Implement basic logging of each step’s input, output, and status.\n",
    "- Prepare branching logic for conditional retries and error recovery.\n",
    "\n",
    "## Phase 5: Basic Workflow Demo\n",
    "- Instantiate the agent.\n",
    "- Add steps:\n",
    "  - Query LM Studio for code generation.\n",
    "  - Read Copilot output.\n",
    "  - (Optional) Validate or transform results.\n",
    "- Loop through all steps with `run_next_step()`.\n",
    "- Print or persist each output for review.\n",
    "\n",
    "## Phase 6: Review & Next Steps\n",
    "- Extend error handling with retry policies and fallback actions.\n",
    "- Build a lightweight UI or CLI for step approval and feedback.\n",
    "- Define success metrics (linting, test coverage, workflow latency).\n",
    "- Integrate additional agents (test runners, deployment bots) and multi-language support."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abef5157",
   "metadata": {},
   "source": [
    "## Phase 1: Environment Setup — Complete\n",
    "- Python 3.11.9 virtual environment configured.\n",
    "- Installed packages: `requests`, `websockets`, `openai`.\n",
    "- Ready for LM Studio integration and file location setup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50bed0b8",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "### Copilot Output File Location Selected\n",
    "- Path: `c:\\Users\\tyler\\source\\repos\\Wulfic\\Orchestrator\\copilot_output.json`\n",
    "- Format: JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27fd78b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import logging\n",
    "import time\n",
    "from typing import Optional\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(filename='lm_studio_api.log', level=logging.INFO, format='%(asctime)s %(levelname)s %(message)s')\n",
    "\n",
    "LM_STUDIO_ENDPOINT = \"http://127.0.0.1:1234/v1/chat/completions\"\n",
    "\n",
    "def query_lm_studio(prompt, model=\"oh-dcft-v3.1-claude-3-5-sonnet-20241022\", timeout=30, max_retries=3, retry_delay=2):\n",
    "    \"\"\"Send a prompt to LM Studio and return the JSON response. Retries on failure.\"\"\"\n",
    "    headers = {\"Content-Type\": \"application/json\"}\n",
    "    payload = {\n",
    "        \"model\": model,\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": prompt}]\n",
    "    }\n",
    "    for attempt in range(1, max_retries + 1):\n",
    "        try:\n",
    "            response = requests.post(LM_STUDIO_ENDPOINT, headers=headers, data=json.dumps(payload), timeout=timeout)\n",
    "            response.raise_for_status()\n",
    "            logging.info(f\"Prompt sent: {prompt}\")\n",
    "            logging.info(f\"Response: {response.text}\")\n",
    "            return response.json()\n",
    "        except requests.exceptions.Timeout:\n",
    "            logging.error(f\"Timeout occurred for prompt: {prompt} (Attempt {attempt})\")\n",
    "            if attempt < max_retries:\n",
    "                time.sleep(retry_delay)\n",
    "            else:\n",
    "                return {\"error\": \"timeout\"}\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            logging.error(f\"HTTP error: {e} (Attempt {attempt})\")\n",
    "            if attempt < max_retries:\n",
    "                time.sleep(retry_delay)\n",
    "            else:\n",
    "                return {\"error\": str(e)}\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Unexpected error: {e} (Attempt {attempt})\")\n",
    "            if attempt < max_retries:\n",
    "                time.sleep(retry_delay)\n",
    "            else:\n",
    "                return {\"error\": str(e)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee8b850",
   "metadata": {},
   "source": [
    "### Next: Define a Simple JSON Message Schema\n",
    "- Agent requests and responses will use a standardized JSON format for communication.\n",
    "- Example schema:\n",
    "```json\n",
    "{\n",
    "  \"request\": {\n",
    "    \"prompt\": \"...\",\n",
    "    \"metadata\": {\n",
    "      \"timestamp\": \"...\",\n",
    "      \"agent_id\": \"...\"\n",
    "    }\n",
    "  },\n",
    "  \"response\": {\n",
    "    \"output\": \"...\",\n",
    "    \"status\": \"success\",\n",
    "    \"error\": null\n",
    "  }\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7199069",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from typing import Optional\n",
    "def build_agent_request(prompt: str, agent_id: str = \"orchestrator\") -> dict:\n",
    "    return {\n",
    "        \"request\": {\n",
    "            \"prompt\": prompt,\n",
    "            \"metadata\": {\n",
    "                \"timestamp\": time.strftime('%Y-%m-%d %H:%M:%S'),\n",
    "                \"agent_id\": agent_id\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "def build_agent_response(output: str, status: str = \"success\", error: Optional[str] = None) -> dict:\n",
    "    return {\n",
    "        \"response\": {\n",
    "            \"output\": output,\n",
    "            \"status\": status,\n",
    "            \"error\": error\n",
    "        }\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35080a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test agent request/response schema and LM Studio query\n",
    "sample_prompt = \"What is the capital of France?\"\n",
    "request_obj = build_agent_request(sample_prompt)\n",
    "print(\"Request object:\", request_obj)\n",
    "\n",
    "response_json = query_lm_studio(sample_prompt)\n",
    "response_obj = build_agent_response(\n",
    "    output=response_json.get('choices', [{}])[0].get('message', {}).get('content', \"No output\"),\n",
    "    status=\"success\" if 'error' not in response_json else \"error\",\n",
    "    error=response_json.get('error')\n",
    "    )\n",
    "print(\"Response object:\", response_obj)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a24a7f",
   "metadata": {},
   "source": [
    "## Phase 2: Communication Bridge — Complete\n",
    "- Implemented and tested `query_lm_studio(prompt)` with error handling and logging.\n",
    "- Defined and validated JSON message schema for agent requests and responses.\n",
    "- All API interactions are logged for debugging.\n",
    "\n",
    "Ready to proceed to Phase 3: Copilot Output Integration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a9e12d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "COPILOT_OUTPUT_PATH = \"c:\\\\Users\\\\tyler\\\\source\\\\repos\\\\Wulfic\\\\Orchestrator\\\\copilot_output.json\"\n",
    "\n",
    "def read_copilot_output(max_retries=3, retry_delay=2):\n",
    "    \"\"\"Read and return the contents of the Copilot output file as a Python object. Retries on failure.\"\"\"\n",
    "    for attempt in range(1, max_retries + 1):\n",
    "        try:\n",
    "            with open(COPILOT_OUTPUT_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "                return json.load(f)\n",
    "        except FileNotFoundError:\n",
    "            logging.error(f\"Copilot output file not found: {COPILOT_OUTPUT_PATH} (Attempt {attempt})\")\n",
    "            if attempt < max_retries:\n",
    "                time.sleep(retry_delay)\n",
    "            else:\n",
    "                return None\n",
    "        except json.JSONDecodeError as e:\n",
    "            logging.error(f\"JSON decode error: {e} (Attempt {attempt})\")\n",
    "            if attempt < max_retries:\n",
    "                time.sleep(retry_delay)\n",
    "            else:\n",
    "                return None\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error reading copilot output: {e} (Attempt {attempt})\")\n",
    "            if attempt < max_retries:\n",
    "                time.sleep(retry_delay)\n",
    "            else:\n",
    "                return None\n",
    "\n",
    "def write_copilot_output(data, max_retries=3, retry_delay=2):\n",
    "    \"\"\"Write the given Python object to the Copilot output file as JSON. Retries on failure.\"\"\"\n",
    "    for attempt in range(1, max_retries + 1):\n",
    "        try:\n",
    "            with open(COPILOT_OUTPUT_PATH, \"w\", encoding=\"utf-8\") as f:\n",
    "                json.dump(data, f, indent=2)\n",
    "            logging.info(f\"Copilot output written to {COPILOT_OUTPUT_PATH}\")\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error writing copilot output: {e} (Attempt {attempt})\")\n",
    "            if attempt < max_retries:\n",
    "                time.sleep(retry_delay)\n",
    "            else:\n",
    "                return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db31c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test writing and reading Copilot output\n",
    "test_data = {\"copilot_output\": [\"Hello, world!\", \"Test entry\"]}\n",
    "write_success = write_copilot_output(test_data)\n",
    "print(\"Write success:\", write_success)\n",
    "read_data = read_copilot_output()\n",
    "print(\"Read data:\", read_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "080edc6c",
   "metadata": {},
   "source": [
    "## Phase 3: Copilot Output Integration — Complete\n",
    "- Implemented and tested `read_copilot_output()` and `write_copilot_output(data)` functions.\n",
    "- File I/O operations verified for correct JSON serialization and error handling.\n",
    "- Ready to standardize file naming conventions and directory structure, then proceed to Phase 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b01af01",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OrchestratorAgent:\n",
    "    def __init__(self, state_file=\"orchestrator_state.json\"):\n",
    "        self.steps = []\n",
    "        self.current_step = 0\n",
    "        self.state_file = state_file\n",
    "        self.load_state()\n",
    "\n",
    "    def add_step(self, description, action):\n",
    "        self.steps.append({\"description\": description, \"action\": action})\n",
    "        self.save_state()\n",
    "\n",
    "    def run_next_step(self, max_retries=3, retry_delay=2):\n",
    "        if self.current_step < len(self.steps):\n",
    "            step = self.steps[self.current_step]\n",
    "            logging.info(f\"Running step {self.current_step + 1}: {step['description']}\")\n",
    "            for attempt in range(1, max_retries + 1):\n",
    "                try:\n",
    "                    result = step[\"action\"]()\n",
    "                    logging.info(f\"Step output: {result}\")\n",
    "                    self.current_step += 1\n",
    "                    self.save_state()\n",
    "                    return result\n",
    "                except Exception as e:\n",
    "                    logging.error(f\"Error in step {self.current_step + 1} (Attempt {attempt}): {e}\")\n",
    "                    if attempt < max_retries:\n",
    "                        time.sleep(retry_delay)\n",
    "                    else:\n",
    "                        logging.error(f\"Step {self.current_step + 1} failed after {max_retries} attempts.\")\n",
    "                        return None\n",
    "        else:\n",
    "            logging.info(\"No more steps to run.\")\n",
    "            return None\n",
    "\n",
    "    def save_state(self, max_retries=3, retry_delay=2):\n",
    "        state = {\n",
    "            \"steps\": [s[\"description\"] for s in self.steps],\n",
    "            \"current_step\": self.current_step\n",
    "        }\n",
    "        for attempt in range(1, max_retries + 1):\n",
    "            try:\n",
    "                with open(self.state_file, \"w\", encoding=\"utf-8\") as f:\n",
    "                    json.dump(state, f, indent=2)\n",
    "                return\n",
    "            except Exception as e:\n",
    "                logging.error(f\"Error saving state (Attempt {attempt}): {e}\")\n",
    "                if attempt < max_retries:\n",
    "                    time.sleep(retry_delay)\n",
    "                else:\n",
    "                    logging.error(f\"Failed to save state after {max_retries} attempts.\")\n",
    "\n",
    "    def load_state(self, max_retries=3, retry_delay=2):\n",
    "        if os.path.exists(self.state_file):\n",
    "            for attempt in range(1, max_retries + 1):\n",
    "                try:\n",
    "                    with open(self.state_file, \"r\", encoding=\"utf-8\") as f:\n",
    "                        state = json.load(f)\n",
    "                    self.current_step = state.get(\"current_step\", 0)\n",
    "                    return\n",
    "                except Exception as e:\n",
    "                    logging.error(f\"Error loading state (Attempt {attempt}): {e}\")\n",
    "                    if attempt < max_retries:\n",
    "                        time.sleep(retry_delay)\n",
    "                    else:\n",
    "                        logging.error(f\"Failed to load state after {max_retries} attempts.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edfef70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test OrchestratorAgent with simple steps\n",
    "def step1():\n",
    "    print(\"Step 1: Query LM Studio\")\n",
    "    return query_lm_studio(\"Write a Python function to add two numbers.\")\n",
    "\n",
    "def step2():\n",
    "    print(\"Step 2: Read Copilot Output\")\n",
    "    return read_copilot_output()\n",
    "\n",
    "agent = OrchestratorAgent()\n",
    "agent.add_step(\"Query LM Studio for code generation\", step1)\n",
    "agent.add_step(\"Read Copilot output\", step2)\n",
    "\n",
    "while agent.current_step < len(agent.steps):\n",
    "    output = agent.run_next_step()\n",
    "    print(f\"Step {agent.current_step}: Output:\", output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fbc95ed",
   "metadata": {},
   "source": [
    "## Phase 4: Orchestrator Agent — Complete\n",
    "- Created `OrchestratorAgent` class with step management, persistent state, and logging.\n",
    "- Tested agent with basic workflow steps.\n",
    "- Ready for Phase 5: Basic Workflow Demo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c380d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phase 5: Basic Workflow Demo\n",
    "def step_query_lm():\n",
    "    prompt = \"Write a Python function to multiply two numbers.\"\n",
    "    response = query_lm_studio(prompt)\n",
    "    code = response.get('choices', [{}])[0].get('message', {}).get('content', \"No output\")\n",
    "    print(\"LM Studio response:\", code)\n",
    "    # Save to Copilot output file\n",
    "    write_copilot_output({\"copilot_output\": [code]})\n",
    "    return code\n",
    "\n",
    "def step_read_copilot():\n",
    "    data = read_copilot_output()\n",
    "    print(\"Copilot output read:\", data)\n",
    "    return data\n",
    "\n",
    "def step_validate_output():\n",
    "    data = read_copilot_output()\n",
    "    # Simple validation: check if output contains 'def'\n",
    "    valid = any('def' in entry for entry in data.get('copilot_output', []))\n",
    "    print(\"Validation result:\", valid)\n",
    "    return valid\n",
    "\n",
    "workflow_agent = OrchestratorAgent()\n",
    "workflow_agent.add_step(\"Query LM Studio for multiplication function\", step_query_lm)\n",
    "workflow_agent.add_step(\"Read Copilot output\", step_read_copilot)\n",
    "workflow_agent.add_step(\"Validate output contains Python function\", step_validate_output)\n",
    "\n",
    "while workflow_agent.current_step < len(workflow_agent.steps):\n",
    "    result = workflow_agent.run_next_step()\n",
    "    print(f\"Step {workflow_agent.current_step}: Result:\", result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d5da9d",
   "metadata": {},
   "source": [
    "## Phase 5: Basic Workflow Demo — Complete\n",
    "- Demonstrated full workflow: querying LM Studio, writing/reading Copilot output, and validating results.\n",
    "- Workflow steps executed and outputs printed for review.\n",
    "- Ready for Phase 6: Review & Next Steps."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f095a46f",
   "metadata": {},
   "source": [
    "## Phase 6: Review & Next Steps\n",
    "- Extend error handling with retry policies and fallback actions for robust workflows.\n",
    "- Build a lightweight UI or CLI for step approval and feedback.\n",
    "- Define and track success metrics (linting, test coverage, workflow latency).\n",
    "- Integrate additional agents (test runners, deployment bots) and multi-language support.\n",
    "\n",
    "You can now iterate on these improvements to further enhance the Orchestrator system."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
